---
layout: post
title: "Yet another article about gamma correction"
date: 2017-11-12
categories: etc
---

<style>
.gradstop {
    height: 80px;
    min-width: 40px;
}

canvas {
    image-rendering: pixelated;
}
#scaled {
    image-rendering: auto;
}
</style>

## What is brightness? ##

This boring gray square is much more interesting than it first appears.

<canvas class="checkers" width="200" height="200"></canvas>

In fact it isn't gray at all; it's a checkerboard of black and white pixels. If
you're reading this article on a high-DPI device like a smart phone or a newish
Macbook, your screen really doesn't like displaying this kind of pattern and you
might see weird artifacts like a faint grid of polka dots or a shimmering
appearance when you scroll the page. Try zooming in on your device until such
effects disappear. Also if you are very close to the screen, you might actually
be able to see the individual pixels, which is also not what we want. Adjust
your viewing distance or squint your eyes. The goal is to have this square
appear like one uniform shade of gray.

I want this image to look correct on your screen because we'll be using it to
strike at the heart of a seriously tricky issue related to how computers display
color: brightness.

Let's imagine how we perceive this square in terms of measurable light. If the
square were solid black, it would be emitting whatever the minimum amount of
light is for your screen (disregarding the independent brightness setting of
your screen). Let's call this minimum amount X. If the square were pure white,
similarly it would be emitting the maximum amount of light, which we'll call Y.
Intuitively, since half of the pixels are white and half are black the overall
light emitted by the square will average out to be halfway between those two
extremes: (X+Y)/2.

But we can also think about this square in another way. It is common knowledge
that pixels store colors as [red, green, blue] triples where each color is an
integer ranging from 0 to 255, often referred to as 24-bit RGB. So our white
pixels are [255, 255, 255] triples and our black pixels are [0, 0, 0] triples.
Again, half are white and half are black so overall it averages out to look like
a square full of a single color. X=0 and Y=255 so (X+Y)/2=127 with rounding. So
that single color should be [127, 127, 127]. Right?

Well let's put those two side-by-side. The checkerboard from above on the left,
and that solid [127, 127, 127] on the right. By the above logic, the two will
look almost exactly the same.

<canvas class="checkers" width="200" height="200"></canvas>
<canvas id="solid" width="200" height="200"></canvas>
...WHAT!?

The reason why they don't look the same is because of an incorrect assumption in
our second argument about 24-bit RGB. Namely, that 127 is halfway between 0 and
255. Sure, it's _mathematically_ halfway between 0 and 255 but we're talking
about _light intensity_, not math. Think back to our original reasoning about
brightness: there is some minimum brightness X and maximum brightness Y.
Certainly 0 should correspond with X and 255 should correspond with Y, but do we
_need_ (0+255)/2 to correspond with (X+Y)/2? Not really. Here's another example
to illustrate this point:

<canvas id="compare" width="256" height="256"></canvas>

In the middle we have two spectra from black to white. If you compare these
spectra with each side of the image, you'll find that they most closely match
their respective sides right in the middle. Above we had two arguments for why
the checkerboard and the 127-gray should give us a "middle" brightness, and here
we see two different spectra where each approach falls in the "middle" of a
spectrum. It turns out that these two spectra correspond with two different (but
equally valid) ways of thinking about brightness.

Notice how the spectrum on the right has many more dark shades than the left
one. The human eye is very good at distinguishing between dark shades of color
and not so good at distinguishing between bright ones; this spectrum is based on
"distinguishability". The shades of gray on this spectrum are chosen such that
the distinguishability of brightness remains (somewhat) constant throughout the
spectrum. The spectrum on the left certainly does not have this property. To me,
at least, it has a quick transition from black to gray at the top, then about
two-thirds of the way down it's essentially white and I can barely tell the
difference from then on. This spectrum is based on measurable light intensity.
Again, the human eye is good at distinguishing between darks and not so good at
brights, and we see that in this spectrum: the closer you look to the top of the
spectrum, the more apparent differences in brightness are.

So these are the two ways of thinking about brightness: perceived brightness
based on distinguishability to the human eye, and measurable light intensity.
For short, I'll call these perceived brightness and light intensity moving
forward. From the previous examples, we learned that 24-bit RGB is actually
based on perceived brightness, because when we look at the "middle" value of
[127, 127, 127], we end up in the middle of the perceived brightness spectrum.

### Takeaway #1 ###

The intensity of a light source (or color) is **not the same thing** as how
bright we perceive that light (or color) to be.

## Gamma and sRGB ##

The relationship between these two ways of thinking about brightness is
well-studied. There is a function that will give you the light intensity for a
perceived brightness and vice versa. For the purposes of this article, we don't
care what this function is exactly, but in general this process of switching
between perceived brightness and light intensity is called gamma correction, and
thus the function is often called a gamma curve.

What complicates the issue somewhat is that there are many different gamma
curves out there. Because in general gamma is a way of converting between how a
color is _stored_ and how a color is _displayed_. However for the purposes of
this article we're only looking at images stored and displayed on computers, and
on computers there's one ubiquitious standard: sRGB. I fudged things earlier
when I was talking about "24-bit RGB". As we've just learned, there's a
difference between perceived brightness and light intensity. We humans obviously
care about the former, but your screen (which has to show you color by
controlling sub-pixel light intensities) only cares about the latter. Since
we've already established that 127-gray corresponds to perceived color, the
_only way_ that your screen can display that color is if your computer can
convert from perceived brightness to light intensity. So I should have said
"24-bit **s**RGB" i.e. RGB in terms of perceived brightness plus a gamma curve
for converting to light intensity.

Almost all computer images store colors using sRGB. Unless your image format has
a specific feature for specifying a different color space, the default is sRGB.
This goes for images taken by most digital cameras, images in your browser,
images in your favorite image editing software, anything!

### Takeaway #2 ###

When you hear **gamma correction**, think "Colors are not being stored as light
intensities and need to be converted." When you hear **sRGB**, think "Colors are
being stored in terms of perceived brightness and there is a standard gamma
curve for converting that to light intensity."

## The problem ##

So far this article has been purely academic and I've been focusing only on
correcting your understanding of brightness. But there are occasionally
situations where _your computer_ needs to understand these different ways of
thinking about brightness. And when it understands them incorrectly, problems
can occur.

Let's look at our familiar checkerboard again, and then right next to it I'll
have your web browser show the same checkerboard shrunk by 25%.

<canvas class="checkers" width="200" height="200"></canvas>
<canvas class="checkers" id="scaled" width="200" height="200" style="width: 100px; height: 100px"></canvas>

...WHAT!?

I told your browser to make it smaller, which it did, but it also made it
**darker** (again, you might need to zoom in on high-DPI devices to see the
effect). Is this the correct behavior? Here's a simple test: keep looking at the
larger checkerboard and back away from your screen until it looks about half as
big. Does it look darker? Nope.

What's happening here is your browser is making the exact same incorrect
assumption we made in the first section. Half of the pixels are black and half
are white, so when we shrink the image the _light intensities_ blend together
and we should end up with a solid square with _light intensity_ halfway between
black and white: (X+Y)/2. But your browser instead says black=0, white=255, so
we get (0+255)/2=127. It's mixing up percieved brightness and light intensity!

To understand why this is incorrect, think about this: when colors blend
together, they blend together _physically_ i.e. with groups of photons mixing
together in the real world. The checkerboard looks gray because the tiny groups
of black photons from the black pixels mix with the tiny groups of white photons
from white pixels. When you "shrink" the square by backing away from your
screen, you aren't changing the way those photons are mixing, you're only
changing the area of the eyeball they are hitting: same mixture, same light
intensity, less area. Or to put it more philosophically, colors exist whether we
perceive them or not, so the process of mixing colors should be done
independently of our perception.

This problem occurs because the smallest color your screen can display is a
single pixel, and the checkerboard is made of individual black and white pixels.
When I ask your browser to display those same pixels in a quarter of the area,
it's forced to mix them together, thus I'm forcing it to demonstrate its
understanding of light intensity.

This problem crops up any time you ask your computer to blend together colors
stored in sRGB. For example, it's well-known that mixing together red and blue
gives you purple, right? How does the browser do?

<canvas id="gradient-test" width="255" height="120"></canvas>

At the top I told the browser to draw a gradient from the most intense red to
the most intense blue. The dark, murky purple we get in the middle of the
gradient is also drawn on its own right below that. This is the same result you
get when you naively mix together sRGB color values (which is what the browser
is doing). On the bottom we have a different gradient that I drew manually based
on mixing light intensities, and above that is the bright purple you get in the
middle.

Bright red + bright blue = dark purple? Ew, no. The bright purple on bottom
makes both intuitive and visual sense. This is the general pattern when
mishandling brightness: colors end up too dark.

In this article, I'm picking examples that clearly point out the error. In real
applications, with real digital images, the difference is usually more subtle.
And when you start getting into photo manipulation where color distortion is
_intended_ in order to achieve a certain look, it can be even harder to tell
what is "correct". But the simple fact is still that your web browser, which was
made by hundreds of highly trained software developers, and is used by billions
of people every day, is mixing colors incorrectly. Which means it's also

* Resizing images incorrectly
* Bluring incorrectly
* Blending semi-transparent layers incorrectly
* Drawing gradients incorrectly

Oh, and it's not just your browser. Remember what I said earlier about sRGB
being a ubiquitous standard in almost every bit of computer software? Yeah,
they're all doing these things wrong too. Well, almost all of them. Software
like Photoshop and ImageMagick are capable of mixing colors correctly, but you
must explicitly specify the sRGB gamma correction; by default they will do it
wrong.

### Takeaway #3 ###

If you're using software to mix colors together, chances are it's doing it wrong.

## Colors ##

But it's not even that simple. So far we've been mainly talking about
shades of gray, it all gets even more complicated when you consider the
RGB channels.

sRGB stores three separate numbers representing the perceived
brightness of red, green, and blue, respectively. All three numbers go
from 0 to 255 so we can represent the brightest red, green, or blue by
drawing a color that has 255 in one channel and 0 in the other two.
We do that below, but pay attention to how you perceive its brightness:

<canvas id="rgb" width="100" height="100"></canvas>

Which of the three appears brightest? Which appears darkest? If your eyes work
like most people's, you perceive green as the brightest and blue as the darkest.
But this is despite them all having the same sRGB value of 255 and thus the same
light intensity! It's our human eyes playing tricks on us again: we perceive the
brightness of light differently depending on its color.

One commonly accepted standard (on which sRGB is based) which quantifies this is
ITU-R Recommandation BT.709, which defines a formula for how bright a color is
based on its RGB light intensities:

L = 0.2126R + 0.7152G + 0.0722B

Notice how the green component is multiplied by a much larger number than the
other two. According to this standard, a pure green color is about 10 times
brighter than a pure blue one! But wait... what does that value L represent? Is
it measurable light intensity or perceived brightness? Confusingly, it's kind of
a mix of both. First of all, this formula is pretty subjective: it's supposed to
reflect the "average" human eye's receptiveness to various colors of light. So
it will certainly be wrong for some observers (think color blindness or
tetrachromacy). So in that sense it's perceived brightness. But notice that I
said it's based on "RGB light intensities", so its output is also in terms of
light intensity. Think about it this way: this formula takes an RGB color in
terms of light intensities and gives you the light intensity of the shade of
gray that has the same perceived brightness as that color.

It's essentially a method of converting a color to black-and-white. When you
make an image black-and-white, you need to set R=G=B for every pixel so that
they are all shades of gray. And ideally you want the brightness of that gray to
match the brightness of the original color. Notice that if R=G=B, plugging into
the formula gives you L=R=G=B. So if you set red, green, and blue to L you get
the desired brightness-preserving black-and-white image. But this is in terms of
light intensity, so we have to convert from and to sRGB if we want to use this
formula with digital images. So the steps should be:

1. Convert from perceived brightness sRGB to light intensity RGB
2. Plug that into the BT.709 formula
3. Convert the resulting light intensity back to perceived brightness
4. Use that one value for red, green, and blue in sRGB

And guess what, again most software does not do this correctly. Many
naively average the sRGB red, green, and blue values (ignoring that
green has a stronger contribution to brightness) while others try to be
smart by using BT.709, but they plug in the sRGB values directly even
though the formula is not designed for that color space. You can see
the results below:

<canvas id="baw" width="400" height="200"></canvas>

The four bottom squares show the green color converted to gray using, from left
to right: sRGB average, sRGB "lightness" (another naive average of channels),
incorrect BT.709 using sRGB, and correct BT.709. As expected, the two sRGB
averaged-based results are far too dark since they don't account for green being
perceived more brightly. The incorrect BT.709 formula is almost right, but again
is a little too dark because sRGB emphasizes darker shades. If you focus on the
border between the green and the gray, the last (correct) square is the least
distinguishable from the color in terms of brightness, indicating that it is a
good match for a black-and-white conversion.

With all of these exampels of sRGB going bad, you might be thinking that it's a
no-brainer to always gamma correct your colors first. But there are other
complications. For example, let's repeat the image from the beginning of the
article comparing the light intensity method with perceived brightness method
but now with black/white replaced with red/blue on the left and with red/yellow
on the right.

<canvas id="compare-rgbrb" width="256" height="256"></canvas>
<canvas id="compare-rgbry" width="256" height="256"></canvas>

Recall how both of these images were made: the left side is a checkerboard
showing a mix of light intensities, then a gradient based on light intensities,
then a naive sRGB-based gradient, then a solid color resulting from a naive sRGB
average. Focus on the left image first: this is just like the red/blue gradient
comparison I did earlier. Again, the left side looks correct since it gives us
the intuitive bright red + bright blue = bright purple result. But now look at
the red/yellow image on the right.

Even with everything I've talked about in this article, my gut still tells me
that the right side of the red/yellow image using incorrect sRGB averaging looks
"correct". But why? Why does the left side of the left image look correct while
the right side of the right image looks correct? Why doesn't a single method of
color mixing always give us the right answer?

The difference is in the colors. Red and blue are separate color channels, so
when you do a gradient between them the red and blue channels are both changing
inversely with each other. The result is a mixture of different amounts of red
and blue together. However yellow is represented by RGB as a mixture of red and
green, so a gradient from red to yellow is a gradient from [255, 0, 0] to [255,
255, 0]: red stays constant while green varies from 0 to 255. When we perceive
the left image from top to bottom, the brightness is affected both by red
becoming less intense and blue becoming more intense. However when we perceive
the right image from top to bottom, we perceive _no_ change in redness so the
_only_ brightness change is as a result from green. And we're back to where we
started: the human eye perceives darker differences better than brighter ones,
so the sRGB gradient spreads out those dark differences more and ends up giving
a color that really is **perceptually halfway** between red and yellow.

This problem existed right from the beginning. Go back and look at the
black/white image from the start of the article. Sure, the left side illustrates
what color is halfway between black and white in terms of light intensities, but
which color actually **looks** like its halfway between black and white? The
right side. It **has** to be the right side because the whole point of sRGB is
to smooth out changes in perceived brightness.

The problem is that sRGB is working double duty. On the one hand, the real
purpose of sRGB is a kind of compression. There are infinitely many different
levels of brightness in the analog real world and we obviously can't store them
all digitally. We have to choose some finite number of light levels: either 256
(per channel, as it is for 24-bit sRGB) or some other finite number. We could
choose those finite levels to be evenly spread out from the darkest light
intensity to the brightest but this would largely be a waste: we know that our
eyes are really bad at distinguishing between similar bright intensities. sRGB
fixes this by devoting more of those levels to the darks than the brights
meaning we can store the maximum number of _discernable differences in
brightness_ within the limited number of levels we have available.

On the other hand, sRGB has also been coopted as a user-friendly way of picking
and working with colors. Because sRGB smooths out perceptual differences in
light intensities, an sRGB gradient from dark to light matches our (incorrect)
expectations of what the dark to light transition should look like: halfway
through the gradient _looks_ halfway between darkest and lightest even though
it's more like 21% brightness in terms of light intensity. This works great if
you lock some channels together and change them in-sync because then the change
in color appearance as you tweak the numerical values matches a change in
perceived brightness. Want to make a shade of gray look half as bright? Halve
all of its RGB values! Want to make a shade of orange look three times as
bright? Triple its green channel! In these limited situations, the wrong
behavior is actually intuitive. The more channels change independently of each
other, the less we get this intuitive matchup and the more strange the sRGB
result looks. The best case for sRGB is all channels changing together (the
original black/white gradient) while the worst case is two channels inverting
(our red/blue example). I must emphasize that this isn't a case of sRGB being
more **correct** in some cases; mixing colors in the sRGB space is **always
incorrect**. This is about sRGB being more **intuitive** for people who do not
understand the difference between perceived brightness and light intensity.

Go back and read the beginning of the article if you have to. Perceived
brightness &ne; light intensity.

So why does mishandling of sRGB color persist? In my opinion, it's a perfect mix
of ignorant programmers, uneducated users, and the status quo. Many programmers
don't know all of this stuff about sRGB and still think that perceived
brightness and light intensity are the same. They write image editing software
and web browsers that mishandle sRGB values. Users of this software also don't
understand this distinction and thus think the software is working correctly
when it draws gradients or mixes colors together. They are incorrectly
unsurprised when simple operations that should be only mixing together colors
end up making their images darker. And lastly, these errors are so common in
essentially all color-handling software out there that we're used to them.
Designers rely on them when picking colors and they expect them when
manipulating images. I'm sure that many developers would consider correct sRGB
handling to be a regression at this point, due to how it would upset their
users' expectations.

### Takeaway #4 ###

sRGB can be a useful tool when changes in color correspond with changes in
perceived brightness, for example when changing a color one channel at a time.
In those cases sRGB will match with the layman's intuition.

But that doesn't make it correct to manipulate colors in sRGB without performing
gamma correction.

## Try it for yourself ##

Here's an interactive gradient with the light intensity method on top and the
incorrect sRGB method on bottom. Click the controls on the sides to change the
colors and get a feel for how the two differ.

<div>
<input id="grad1" class="gradstop" type="color" value="#000000" oninput="update_interactive()">
<canvas id="interactive" height="80" width="256"></canvas>
<input id="grad2" class="gradstop" type="color" value="#ffffff" oninput="update_interactive()">
</div>

If you want to try out correct color manipulation, a great way to get started is
with [ImageMagick][im]. If you want to use your prefered image manipulation
software, you're going to have to look up specific instructions for it
elsewhere.

[im]: https://www.imagemagick.org

For most ImageMagick commands, you can get it to do the right thing by prefixing
your operations with `-colorspace RGB` to perform the gamma correction and then
preceding your final output with `-colorspace sRGB` to undo it for saving. For
example, this works for both resizing and blurs:

    convert inputfile.png -colorspace RGB -resize 800 -colorspace sRGB outputfile.png

    convert inputfile.png -colorspace RGB -gaussian-blur 0x8 -colorspace sRGB outputfile.png

Gradient generation is a little different because ImageMagick creates all
gradients in sRGB space. Instead you have to force it to reinterpret the image
as light-intensity RGB (without performing gamma correction) so that the final
`-colorspace sRGB` gamma encodes it correctly:

    convert -size 200x200 gradient:red-blue -set colorspace RGB -colorspace sRGB outputfile.png

Converting an image to black and white is also different. If you specify the
BT.709 formula it does the gamma correction for you, but the output result is
light intensity so you still need the sRGB conversion at the end:

    convert inputfile.png -grayscale rec709luminance -colorspace sRGB outputfile.png

**Note:** ImageMagick also provides the **incorrect** implementation of the
formula, which directly plugs in the sRGB values without gamma correction (they
call this `rec709luma`). Unfortunately, that is the formula used by their
default "gray" colorspace, and it's also the one recommended in their
documentation.

## Exceptions ##

Annoyingly, there are exceptional cases.

The first and probably less important one is color inversion. This is a pretty
weird, uncommon operation but it's actually what led me down this rabbit hole in
the first place. Obviously when we invert an image we want the colors to...
invert. Things that were very red before should be very not red after. Black
should become white, etc. But with what we know about sRGB, gamma correction
will actually hurt us here. Let's do an example. We start with a black/white
sRGB gradient which gives us a smooth transition between black and white where
the halfway point is perceptually halfway between black and white. What will
happen if we gamma correct this gradient, do the inversion in terms of light
intensity and then convert back to sRGB? Look at the result below, with the
original gradient on top and the inverted one underneath:

<canvas id="invert" width="256" height="80"></canvas>

The result looks like a light intensity-based gradient! Why is this bad? Well
remember that the dark colors are where the human eye best perceives details.
We've taken a gradient that had a perceptually smooth transition and&mdash;by
inverting it in terms of light intensity&mdash;crammed all of the details into
what were the very brightest and least-distinguishable colors before. And all of
the darker shades in the lower half which used to be easily distinguishable are
now nearly-identical white! We intended to just invert the colors, but we ended
up inverting the details as well.

The trouble is that unlike color mixing, bluring, or image resizing, color
inversion doesn't have a real-world analogue so there's no ground truth to
compare to. The most reasonable result I can think of is one that inverts colors
while maintaining perceptual differences between them so that details don't get
lost/added as a side-effect. Since sRGB is perception-based, the naive inversion
of the sRGB channels actually does a pretty good job. The gradient gets flipped,
so the perceptual differences are maintained:

<canvas id="invertrgb" width="256" height="80"></canvas>

The only improvement I can think to make is that this naive inversion doesn't
take into account the BT.709 formula. I can imagine it being desirable that
inverting a color also inverts its perceived brightness; the simple sRGB
inversion can't do this because it treats each color channel equally (it works
for this simple black/white gradient, but not in general). But off the top of my
head I can't think of any easy way to do this, and I imagine it could actually
be pretty expensive so the sRGB approach is a good compromise for now.

The other, more tricky exception is font rendering. Fonts employ a number of
tricks to maintain readability at small sizes. The simplest trick is
anti-aliasing, which the font rendering engine applies to edges at small sizes
to keep them looking smooth. The engine might also mess with pixel and sub-pixel
alignment so that the edges of letters align with the pixel grid and are thus
clearer. Font designers can also design their glyphs to actually change shape at
smaller sizes, for example removing artistic flourishes that would hamper
readability.

In one sense this does have a real world analogue. A small font is kind of like
a shrunken font, so in that sense it should use gamma correction just like image
resizing. But the goal of font rendering is to get a readable result, not a
real-world light-accurate one. If the inaccurate result is more readable it's
the right result. What complicates this is that some font rendering engines do
not perform gamma correction when blending colors to make the edges of the font
look smooth. At large sizes this is not much of an issue because it just makes
the edges of the font look slightly less smooth. But if font designers design
their fonts around these incorrect engines, they might be relying on that
incorrect color blending at the small sizes to improve readability. So you can't
fix the larger case (which would make edges look smoother and more realistic)
without breaking the smaller case (making small fonts less readable).

## Further reading ##

Here are links to where I did most of my research:

[Gamma error in picture scaling][1]. A very extensive article with a focus on
image resizing. Good examples of real world images with noticable distortion due
to incorrect color space handling.

[Computer Color is Broken][2]. A nicely animated explanation with a focus on
image bluring.

[What every coder should know about gamma][3]. Really thorough article with even
more examples than I have here.

[Resizing with Colorspace Correction][4]. The ImageMagick manual's section on
correctly resizing images, with some notes about other linear color spaces.

Lastly, if you're interested in how the math works, you can read the source for
this page in your browser. All of the images in this article are procedurally
generated in javascript so you can see how I do the gamma-correct gradients and
such.

[1]: http://www.ericbrasseur.org/gamma.html
[2]: https://www.youtube.com/watch?v=LKnqECcg6Gw
[3]: http://blog.johnnovak.net/2016/09/21/what-every-coder-should-know-about-gamma/
[4]: http://www.imagemagick.org/Usage/resize/#resize_colorspace

## For the pedants ##

I fudged a lot of stuff in this article. It kind of drives me crazy how
widespread this issue is and yet how little attention it gets, so I simplified
things a bit to get the point across quicker. But if you really care about
technical details, read on.

"Light intensity" and "perceived brightness" are not the correct terms for this
stuff. Usually people described sRGB as a "nonlinear RGB" color space. And when
you gamma correct sRGB to get light intensities, that's "linear RGB". I find
these terms a little vague because they are implicitly referring to light
intensities: sRGB has nonlinear light intensity and when you gamma correct it
you (obviously) get linear light intensity because that's what gamma correction
is. But if you think about it in terms of perceived brightness then sRGB is the
linear one and the "linear RGB" is now nonlinear! I find that thinking linearly
is more intuitive, so I named both of them by the context in which they are
linear. sRGB is linear in the perceptual space and "linear RGB" is linear in the
light intensity space and both of them are nonlinear when viewed from the
perspective of the other space.

There is a large class of software that does color blending right: graphics
drivers. The code that runs on graphics processors to compute colors all runs in
a linear RGB color space so that they blend correctly. Though it's still
possible to mess it up: when loading an sRGB image onto the graphics card you
still need to tell the driver to do the gamma correction. Otherwise it will load
the sRGB values directly and will end up doing linear operations on nonlinear
values!

You could argue that sRGB wasn't designed as a compression scheme, it actually
has to do with CRT voltages and the whole perceived brightness thing was a happy
accident. But I believe that coincidence is why it has stuck around so long and
why this gamma correction issue is so hard to teach people about. So it might as
well be the reason for its existence.

<script>
"use strict";

// fill canvases pixel-by-pixel
function procedural_canvas(selector, callback) {
	var canvases = document.querySelectorAll(selector);
	for (var k = 0; k < canvases.length; ++k) {
		var canvas = canvases[k];
		var width = canvas.width;
		var height = canvas.height;

		var ctx = canvas.getContext('2d');

		var image = new ImageData(width, height);
		for (var y = 0; y < height; ++y) {
			for (var x = 0; x < width; ++x) {
				var color = callback(y, x, height, width);
				for (var c = 0; c < 4; ++c) image.data[(y * width + x) * 4 + c] = color[c];
			}
		}
		ctx.putImageData(image, 0, 0);
	}
}

var alpha = 0.055;

// nonlinear 0-1 to linear 0-1
function gamma2linear(comp) {
	if (comp < 0.04045) return comp / 12.92;
	return Math.pow((comp + alpha) / (1 + alpha), 2.4);
}

// linear 0-1 to nonlinear 0-1
function linear2gamma(comp) {
	if (comp <= 0.0031308) return comp * 12.92;
	return (1 + alpha) * Math.pow(comp, 1 / 2.4) - alpha;
}

function clamp(min, x, max) {
	return Math.min(Math.max(x, min), max);
}

// 0-1 to 0-255 integer
function to8bit(x) {
	return clamp(0, Math.round(x * 255), 255);
}

// #abcdef color to [0-1,0-1,0-1] color
function hextonum(x) {
	return [parseInt(x.slice(1, 3), 16) / 255, parseInt(x.slice(3, 5), 16) / 255, parseInt(x.slice(5, 7), 16) / 255];
}

// update the interactive gradient based on the color picker values
function update_interactive() {
	var grad1 = hextonum(document.getElementById('grad1').value);
	var grad2 = hextonum(document.getElementById('grad2').value);

	var grad1l = grad1.map(gamma2linear);
	var grad2l = grad2.map(gamma2linear);

	procedural_canvas('#interactive', function(y, x, h, w) {
		var p = x / w;

		var g1 = grad1;
		var g2 = grad2;

		if (y < h / 2) {
			g1 = grad1l;
			g2 = grad2l;
		}

		var color = [];
		for (var c = 0; c < 3; ++c) {
			color[c] = g1[c] * (1 - p) + g2[c] * p;
		}

		if (y < h / 2) {
			for (var c = 0; c < 3; ++c) {
				color[c] = linear2gamma(color[c]);
			}
		}

		return [to8bit(color[0]), to8bit(color[1]), to8bit(color[2]), 255];
	});
}
update_interactive();

procedural_canvas('.checkers', function(y, x) {
	var color = (y + x) % 2 ? 0 : 255;
	return [color, color, color, 255];
});

procedural_canvas('#solid', function() {
	return [127, 127, 127, 255];
});
procedural_canvas('#compare', function(y, x, h, w) {
	var edgesize = w / 4;
	if (x <= edgesize) {
		var color = (y + x) % 2 ? 0 : 255;
		return [color, color, color, 255];
	}
	if (x > edgesize && x <= w / 2) {
		var color = to8bit(linear2gamma(y / (h - 1)));
		return [color, color, color, 255];
	}
	if (x > w / 2 && x < w - edgesize) {
		var c = to8bit(y / (h - 1));
		return [c, c, c, 255];
	}
	return [127, 127, 127, 255];
});

procedural_canvas('#gradient-test', function(y, x, h, w) {
	if (y > 3 * h / 4) {
		return [to8bit(linear2gamma(1 - x / w)), 0, to8bit(linear2gamma(x / w)), 255];
	}
	if (x < w / 3) return [255, 0, 0, 255];
	if (x > 2 * w / 3) return [0, 0, 255, 255];
	if (y < h / 2) return [127, 0, 127, 255];
	var c = to8bit(linear2gamma(0.5));
	return [c, 0, c, 255];
});
var canvas = document.getElementById('gradient-test');
var ctx = canvas.getContext('2d');
var grad = ctx.createLinearGradient(0, 0, canvas.width, 0);
grad.addColorStop(0, "red");
grad.addColorStop(1, "blue");
ctx.fillStyle = grad;
ctx.fillRect(0, 0, canvas.width, canvas.height / 4);

procedural_canvas('#rgb', function(y, x, h, w) {
	x = x - w / 2;
	y = h / 2 - y;

	if (x * x + y * y > w * w / 4) return [0, 0, 0, 0];

	var theta = Math.atan2(y, x);

	if (theta < -Math.PI/3) return [255, 0, 0, 255];
	if (theta < Math.PI/3) return [0, 255, 0, 255];
	return [0, 0, 255, 255];
});
procedural_canvas("#baw", function(y, x, h, w) {
	var color = [28, 130, 60];
	if (y < h / 2) return [color[0], color[1], color[2], 255];
	var l;
	if (x < w / 4) {
		l = Math.round((color[0] + color[1] + color[2]) / 3);
	}
	else if (x < w / 2) {
		l = (Math.max.apply(this, color) + Math.min.apply(this, color)) / 2;
	}
	else if (x < 3 * w / 4) {
		l = Math.round(color[0] * 0.2126 + color[1] * 0.7152 + color[2] * 0.0722);
	}
	else {
		l = to8bit(linear2gamma(gamma2linear(color[0] / 255) * 0.2126 + gamma2linear(color[1] / 255) * 0.7152 + gamma2linear(color[2] / 255) * 0.0722));
	}
	return [l, l, l, 255];
});
procedural_canvas('#compare-rgbry', function(y, x, h, w) {
	var edgesize = w / 4;
	if (x <= edgesize) {
		var color = (y + x) % 2 ? 0 : 255;
		return [255, color, 0, 255];
	}
	if (x > edgesize && x <= w / 2) {
		var color = to8bit(linear2gamma(y / (h - 1)));
		return [255, color, 0, 255];
	}
	if (x > w / 2 && x < w - edgesize) {
		var c = to8bit(y / (h - 1));
		return [255, c, 0, 255];
	}
	return [255, 127, 0, 255];
});
procedural_canvas('#compare-rgbrb', function(y, x, h, w) {
	var edgesize = w / 4;
	if (x <= edgesize) {
		if ((y + x) % 2) return [255, 0, 0, 255];
		return [0, 0, 255, 255];
	}
	if (x > edgesize && x <= w / 2) {
		var c1 = to8bit(linear2gamma(y / (h - 1)));
		var c2 = to8bit(linear2gamma(1 - y / (h - 1)));
		return [c2, 0, c1, 255];
	}
	if (x > w / 2 && x < w - edgesize) {
		var c = to8bit(y / (h - 1));
		return [255 - c, 0, c, 255];
	}
	return [127, 0, 127, 255];
});
procedural_canvas('#invert', function(y, x, h, w) {
	if (y < h / 2) {
		var c = to8bit(x / (w - 1));
		return [c, c, c, 255];
	}

	var c = to8bit(linear2gamma(1 - gamma2linear(x / (w - 1))));
	return [c, c, c, 255];
});
procedural_canvas('#invertrgb', function(y, x, h, w) {
	var c = to8bit(x / (w - 1));
	if (y < h / 2) return [c, c, c, 255];
	return [255 - c, 255 - c, 255 - c, 255];
});

</script>

---
layout: post
title: "Why we should fear AI"
categories: etc
---

Article about how AI isn't dangerous in the way people usually think

Address the main assumptions:

1. "intelligence" is on some linear scale, so there exists some intelligence that is "more intelligent" than us (not just faster thinking, or having more memory, or just alien/different)
2. we can design such an intelligence artificially
3. such an AI would be able to design an even "more intelligent" AI, and so on for all such greater intelligences
4. there is no limit on the amount of power/influence one gains as their intelligence increases, thus an infinitely intelligent agent would wield infinite power/influence in the world

Machine learning is a way to construct complicated functions. Explain what
functions is.

Every AI breakthrough is something that is easy to translate into a complicated
function, so machine learning is very succesful right now.

Link to Vox video about AI which is pretty balanced

The real danger is from changes in soceity as a response to enhanced machine
learning. The danger is in misuse of AI or trusting these complicated functions
too much.

The limitations of a machine-learned function are unknown and (by nature) almost
unknowable because the whole point is the domain is too big to study.

